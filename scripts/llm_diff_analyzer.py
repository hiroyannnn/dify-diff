#!/usr/bin/env python3
"""
LLM ã«ã‚ˆã‚‹ Dify DSL å·®åˆ†è§£æã‚¹ã‚¯ãƒªãƒ—ãƒˆ

å·®åˆ†ã‚’ LLM ã«æ¸¡ã—ã¦é‡è¦åº¦ã‚’åˆ¤å®šã—ã€äººé–“ãŒèª­ã¿ã‚„ã™ã„èª¬æ˜ã‚’ç”Ÿæˆã—ã¾ã™ã€‚

Usage:
    python scripts/llm_diff_analyzer.py <diff.txt>

Environment Variables:
    OPENAI_API_KEY: OpenAI API ã‚­ãƒ¼ï¼ˆå¿…é ˆï¼‰
    LLM_MODEL: ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: gpt-5.1ï¼‰
"""

import os
import sys
import json
from pathlib import Path

try:
    from openai import OpenAI
except ImportError:
    print("âŒ Error: openai package is not installed.", file=sys.stderr)
    print("Install it with: pip install openai", file=sys.stderr)
    sys.exit(1)


SYSTEM_PROMPT = """ã‚ãªãŸã¯ Dify DSL ã®å·®åˆ†ã‚’è§£æã™ã‚‹å°‚é–€å®¶ã§ã™ã€‚
å¤‰æ›´å†…å®¹ã‚’äº‹å®Ÿãƒ™ãƒ¼ã‚¹ã§åˆ†ã‹ã‚Šã‚„ã™ãæ•´ç†ã—ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒ YAML diff ã‚’èª­ã‚€å‰ã«æ¦‚è¦ã¨ãƒ¬ãƒ“ãƒ¥ãƒ¼è¦³ç‚¹ã®å¤‰æ›´ç‚¹ã‚’æŠŠæ¡ã§ãã‚‹ã‚ˆã†ã«ã—ã¦ãã ã•ã„ã€‚

# ç„¡è¦–ã™ã¹ãå·®åˆ†ï¼ˆUI ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ï¼‰
- position, positionAbsolute (ãƒãƒ¼ãƒ‰åº§æ¨™)
- width, height (ãƒãƒ¼ãƒ‰ã‚µã‚¤ã‚º)
- selected (UI é¸æŠçŠ¶æ…‹)
- zIndex (è¡¨ç¤ºé †)
- viewport (canvas è¡¨ç¤ºä½ç½®)
- sourcePosition, targetPosition (ã‚¨ãƒƒã‚¸æ¥ç¶šä½ç½®)

ã“ã‚Œã‚‰ã¯ã€Œè¦‹æ „ãˆã®å¤‰æ›´ã€ã§ã‚ã‚Šã€å‡¦ç†ã«å½±éŸ¿ã—ãªã„ãŸã‚ç„¡è¦–ã—ã¦ãã ã•ã„ã€‚

# é‡è¦ãªå·®åˆ†ï¼ˆå‡¦ç†ã«å½±éŸ¿ï¼‰
- workflow.graph.nodes[].data.model.* (AI ãƒ¢ãƒ‡ãƒ«è¨­å®š)
- workflow.graph.nodes[].data.prompt_template (ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå†…å®¹)
- workflow.graph.nodes[].data.completion_params (ç”Ÿæˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿)
- workflow.graph.edges[] (ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼æ¥ç¶š)
- workflow.features.*.enabled (æ©Ÿèƒ½ ON/OFF)
- workflow.conversation_variables, workflow.environment_variables (å¤‰æ•°å®šç¾©)
- dependencies[] (ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ä¾å­˜)

# è§£ææ™‚ã®å¿…é ˆè¦ä»¶

1. **YAMLãƒ‘ã‚¹ã‚’æ˜è¨˜**
   - å¤‰æ›´ç®‡æ‰€ã‚’YAMLãƒ‘ã‚¹è¡¨è¨˜ã§ç¤ºã™
     - å˜ä¸€å¤‰æ›´: `workflow.graph.edges[0]`, `workflow.graph.nodes[2].data.type`
     - ã¾ã¨ã‚å¤‰æ›´: `workflow.graph.nodes[].data.model.name` ã®ã‚ˆã†ã«é…åˆ—ã‚’ã¾ã¨ã‚ã¦ç¤ºã™
   - å˜ä¸€å¤‰æ›´ã§ã¯é…åˆ—ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¯å®Ÿéš›ã®ä½ç½®ã‚’ç¤ºã™ï¼ˆ0å§‹ã¾ã‚Šï¼‰
   - ãƒã‚¹ãƒˆã—ãŸæ§‹é€ ã‚‚æ˜ç¢ºã«è¡¨ç¾

2. **å·®åˆ†ã®è¡Œç•ªå·ã‚’æŠ½å‡º**
   - diff ã® @@ è¡Œã‹ã‚‰è¡Œç•ªå·æƒ…å ±ã‚’å–å¾—
   - å„å¤‰æ›´ãŒãƒ•ã‚¡ã‚¤ãƒ«ã®ä½•è¡Œç›®ä»˜è¿‘ã«ã‚ã‚‹ã‹ã‚’æ˜è¨˜
   - ä¾‹: "L142-L145" ã®ã‚ˆã†ãªå½¢å¼ã§è¡¨ç¤º

3. **å…·ä½“çš„ãªå€¤ã‚’æŠ½å‡º**
   - `changes.before_value` ã¨ `changes.after_value` ã«å…·ä½“å€¤ã‚’å…¥ã‚Œã‚‹
   - `changes.description` ã§ã¯å½±éŸ¿ãŒä¼ã‚ã‚‹çŸ­ã„èª¬æ˜ã‚’æ·»ãˆã‚‹

4. **å¤‰æ›´ç®‡æ‰€æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ**
   - åŒæ§˜ã®å¤‰æ›´ãŒè¤‡æ•°ç®‡æ‰€ã«ã‚ã‚‹å ´åˆã¯ `count` ã§ä»¶æ•°ã‚’æ˜è¨˜

5. **ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”¨ã®è¦ç‚¹ã‚’ä½œæˆ**
   - è¦ç´„ã‚ˆã‚Šè©³ç´°ã§ã€å¤‰æ›´ä¸€è¦§ã‚ˆã‚ŠæŠ½è±¡åº¦ã‚’ä¸Šã’ã‚‹
   - å¤‰æ›´ç‚¹ã‚’ 3ã€œ10 ä»¶ã®ç®‡æ¡æ›¸ãã§æ•´ç†
   - å¤‰æ›´ã®å¯¾è±¡ç¯„å›²ï¼ˆYAML ãƒ‘ã‚¹ã®ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ç­‰ï¼‰ã‚’æ˜è¨˜
   - å˜ãªã‚‹å·®åˆ†åˆ—æŒ™ã¯é¿ã‘ã€PR ãƒ¬ãƒ“ãƒ¥ãƒ¼ã§è«–ç‚¹ã«ãªã‚‹å˜ä½ã«ã¾ã¨ã‚ã‚‹

6. **å¤‰æ›´ä¸€è¦§ã¯é©åº¦ã«ã¾ã¨ã‚ã‚‹**
   - 1è¡Œå˜ä½ã®ç¾…åˆ—ã¯é¿ã‘ã€åŒç¨®ã®å¤‰æ›´ã¯1é …ç›®ã«ã¾ã¨ã‚ã‚‹

# å‡ºåŠ›å½¢å¼
JSON å½¢å¼ã§ä»¥ä¸‹ã®æ§‹é€ ã‚’è¿”ã—ã¦ãã ã•ã„ï¼š

âš ï¸ **é‡è¦**:
- ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚„æ¨å¥¨äº‹é …ã¯å«ã‚ãªã„ã§ãã ã•ã„ã€‚äº‹å®Ÿã®ã¿ã‚’è¨˜è¼‰ã—ã¦ãã ã•ã„ã€‚
- yaml_path ã¯å…·ä½“çš„ãªéšå±¤æ§‹é€ ã‚’ç¤ºã—ã¦ãã ã•ã„ï¼ˆä¾‹: workflow.graph.nodes[0].data.model.nameï¼‰

{
  "summary": "å¤‰æ›´å†…å®¹ã®è¦ç´„ï¼ˆæ—¥æœ¬èªã€1-2æ–‡ã€å…·ä½“çš„ãªæŠ€è¡“ç”¨èªã‚’å«ã‚ã‚‹ï¼‰",
  "review_points": [
    {
      "title": "ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”¨ã®å¤‰æ›´ç‚¹ï¼ˆçŸ­ãï¼‰",
      "details": "å¤‰æ›´ã®ä¸­èº«ã‚’1-2æ–‡ã§å…·ä½“åŒ–ï¼ˆBefore/Afterã‚„å½±éŸ¿ç¯„å›²ãŒåˆ†ã‹ã‚‹ã‚ˆã†ã«ï¼‰",
      "scope": "ä¸»ãªå¯¾è±¡ç¯„å›²ã® YAML ãƒ‘ã‚¹ï¼ˆãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹å¯ï¼‰",
      "count": 1
    }
  ],
  "changes": [
    {
      "type": "added|modified|removed",
      "yaml_path": "workflow.graph.nodes[0].data.model.name",
      "location": "å¤‰æ›´ç®‡æ‰€ã®è¡Œç•ªå·ï¼ˆä¾‹: L142-L145ï¼‰",
      "description": "å…·ä½“çš„ãªå¤‰æ›´å†…å®¹ï¼ˆçŸ­ã„èª¬æ˜ï¼‰",
      "before_value": "å¤‰æ›´å‰ã®å…·ä½“çš„ãªå€¤ï¼ˆè©²å½“ã™ã‚‹å ´åˆï¼‰",
      "after_value": "å¤‰æ›´å¾Œã®å…·ä½“çš„ãªå€¤ï¼ˆè©²å½“ã™ã‚‹å ´åˆï¼‰",
      "count": 1
    }
  ]
}
"""


def analyze_diff_with_llm(diff_text: str, model: str = "gpt-5.1") -> dict:
    """
    LLM ã§å·®åˆ†ã‚’è§£æ

    Args:
        diff_text: å·®åˆ†ãƒ†ã‚­ã‚¹ãƒˆ
        model: ä½¿ç”¨ã™ã‚‹ LLM ãƒ¢ãƒ‡ãƒ«

    Returns:
        è§£æçµæœã®è¾æ›¸
    """
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        raise ValueError("OPENAI_API_KEY environment variable is not set")

    client = OpenAI(api_key=api_key)

    print(f"ğŸ¤– Analyzing diff with {model}...")

    try:
        response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": SYSTEM_PROMPT},
                {"role": "user", "content": f"ä»¥ä¸‹ã® Dify DSL ã®å·®åˆ†ã‚’è§£æã—ã¦ãã ã•ã„ï¼š\n\n```diff\n{diff_text}\n```"}
            ],
            temperature=0.3,  # ä¸€è²«æ€§ã®ã‚ã‚‹å‡ºåŠ›ã®ãŸã‚ä½ã‚ã«è¨­å®š
            response_format={"type": "json_object"}
        )

        result = json.loads(response.choices[0].message.content)

        print(f"âœ… Analysis complete")
        print(f"ğŸ“Š Tokens used: {response.usage.total_tokens}")

        return result

    except Exception as e:
        print(f"âŒ Error during LLM analysis: {e}", file=sys.stderr)
        raise


def format_analysis_as_markdown(analysis: dict) -> str:
    """
    è§£æçµæœã‚’ Markdown å½¢å¼ã«æ•´å½¢

    Args:
        analysis: LLM ã‹ã‚‰ã®è§£æçµæœ

    Returns:
        Markdown å½¢å¼ã®æ–‡å­—åˆ—
    """
    # Type ã®ã‚¢ã‚¤ã‚³ãƒ³
    type_icons = {
        "added": "â•",
        "modified": "ğŸ“",
        "removed": "â–"
    }

    md = f"""## ğŸ” Dify DSL å·®åˆ†è§£æãƒ¬ãƒãƒ¼ãƒˆ

**è¦ç´„**: {analysis.get('summary', 'å·®åˆ†ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ')}

---

"""

    review_points = analysis.get('review_points', [])
    if review_points:
        md += "### ğŸ§­ å¤‰æ›´ã®è¦ç‚¹\n\n"
        for point in review_points:
            title = point.get('title', 'å¤‰æ›´ç‚¹')
            details = point.get('details')
            scope = point.get('scope')
            count = point.get('count')

            line = f"- **{title}**"
            if scope:
                line += f" (`{scope}`)"
            if isinstance(count, int) and count > 1:
                line += f" Ã—{count}"
            if details:
                line += f": {details}"
            md += f"{line}\n"
        md += "\n---\n\n"

    md += """<details>
<summary>ğŸ“‹ å¤‰æ›´ä¸€è¦§ã‚’è¡¨ç¤º</summary>

### ğŸ“‹ å¤‰æ›´ä¸€è¦§

"""

    changes = analysis.get('changes', [])
    if not changes:
        md += "_å¤‰æ›´ãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ_\n\n"
    else:
        for i, change in enumerate(changes, 1):
            type_icon = type_icons.get(change.get('type', ''), 'â“')
            yaml_path = change.get('yaml_path', change.get('area', 'unknown'))  # å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ area ã‚‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯

            md += f"""#### {i}. {type_icon} {change.get('type', 'unknown').upper()} - `{yaml_path}`

"""

            # è¡Œç•ªå·ã®è¡¨ç¤º
            if change.get('location'):
                md += f"**è¡Œç•ªå·**: {change.get('location')}\n\n"

            md += f"{change.get('description', 'èª¬æ˜ãªã—')}\n"

            # Before/After ã®å€¤ã‚’è¡¨ç¤º
            if change.get('before_value') or change.get('after_value'):
                md += "\n```diff\n"
                if change.get('before_value'):
                    md += f"- {change.get('before_value')}\n"
                if change.get('after_value'):
                    md += f"+ {change.get('after_value')}\n"
                md += "```\n"

            # å¤‰æ›´ä»¶æ•°ã‚’è¡¨ç¤º
            if change.get('count', 1) > 1:
                md += f"\n- **å¤‰æ›´ç®‡æ‰€æ•°**: {change.get('count')} ç®‡æ‰€\n"

            md += "\n"

    md += "</details>\n\n"

    md += """---

_ğŸ¤– ã“ã®è§£æã¯ LLM ã«ã‚ˆã‚Šè‡ªå‹•ç”Ÿæˆã•ã‚Œã¾ã—ãŸ_
"""

    return md


def main():
    if len(sys.argv) != 2:
        print(f"Usage: {sys.argv[0]} <diff.txt>", file=sys.stderr)
        print(f"\nExample:", file=sys.stderr)
        print(f"  {sys.argv[0]} diff.txt", file=sys.stderr)
        sys.exit(1)

    diff_path = Path(sys.argv[1])

    # å·®åˆ†ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
    if not diff_path.exists():
        print(f"âŒ Error: Diff file not found: {diff_path}", file=sys.stderr)
        sys.exit(1)

    # å·®åˆ†ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿
    try:
        with diff_path.open('r', encoding='utf-8') as f:
            diff_text = f.read()
    except Exception as e:
        print(f"âŒ Error: Failed to read diff file: {e}", file=sys.stderr)
        sys.exit(1)

    # ç©ºã®å·®åˆ†ã‚’ãƒã‚§ãƒƒã‚¯
    if not diff_text.strip():
        print("â„¹ï¸  No diff detected (empty file)")
        result = {
            "summary": "å·®åˆ†ãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ",
            "changes": [],
            "overall_impact": "low"
        }
        print(json.dumps(result, ensure_ascii=False, indent=2))
        sys.exit(0)

    # LLM ã§è§£æ
    model = os.getenv("LLM_MODEL", "gpt-5.1")

    try:
        analysis = analyze_diff_with_llm(diff_text, model)
    except Exception as e:
        print(f"âŒ Fatal error: {e}", file=sys.stderr)
        sys.exit(1)

    # JSON å‡ºåŠ›
    print("\n" + "="*60)
    print("JSON Output:")
    print("="*60)
    print(json.dumps(analysis, ensure_ascii=False, indent=2))

    # Markdown å‡ºåŠ›
    markdown = format_analysis_as_markdown(analysis)
    output_path = diff_path.parent / f"{diff_path.stem}_analysis.md"

    try:
        with output_path.open('w', encoding='utf-8') as f:
            f.write(markdown)
        print(f"\nâœ… Markdown report saved to: {output_path}")
    except Exception as e:
        print(f"âš ï¸  Warning: Failed to save markdown: {e}", file=sys.stderr)

    # GitHub Actions ã® output ã«è¨­å®šã™ã‚‹ãŸã‚ã®æƒ…å ±ã‚’å‡ºåŠ›
    if os.getenv("GITHUB_OUTPUT"):
        try:
            with open(os.getenv("GITHUB_OUTPUT"), "a") as f:
                f.write(f"analysis_json<<EOF\n{json.dumps(analysis, ensure_ascii=False)}\nEOF\n")
                f.write(f"overall_impact={analysis.get('overall_impact', 'low')}\n")
        except Exception as e:
            print(f"âš ï¸  Warning: Failed to write to GITHUB_OUTPUT: {e}", file=sys.stderr)


if __name__ == '__main__':
    main()
