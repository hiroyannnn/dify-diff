#!/usr/bin/env python3
"""
LLM ã«ã‚ˆã‚‹ Dify DSL å·®åˆ†è§£æã‚¹ã‚¯ãƒªãƒ—ãƒˆ

å·®åˆ†ã‚’ LLM ã«æ¸¡ã—ã¦é‡è¦åº¦ã‚’åˆ¤å®šã—ã€äººé–“ãŒèª­ã¿ã‚„ã™ã„èª¬æ˜ã‚’ç”Ÿæˆã—ã¾ã™ã€‚

Usage:
    python scripts/llm_diff_analyzer.py <diff.txt>

Environment Variables:
    OPENAI_API_KEY: OpenAI API ã‚­ãƒ¼ï¼ˆå¿…é ˆï¼‰
    LLM_MODEL: ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: gpt-4o-miniï¼‰
"""

import os
import sys
import json
from pathlib import Path

try:
    from openai import OpenAI
except ImportError:
    print("âŒ Error: openai package is not installed.", file=sys.stderr)
    print("Install it with: pip install openai", file=sys.stderr)
    sys.exit(1)


SYSTEM_PROMPT = """ã‚ãªãŸã¯ Dify DSL ã®å·®åˆ†ã‚’è§£æã™ã‚‹å°‚é–€å®¶ã§ã™ã€‚

# ç„¡è¦–ã™ã¹ãå·®åˆ†ï¼ˆUI ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ï¼‰
- position, positionAbsolute (ãƒãƒ¼ãƒ‰åº§æ¨™)
- width, height (ãƒãƒ¼ãƒ‰ã‚µã‚¤ã‚º)
- selected (UI é¸æŠçŠ¶æ…‹)
- zIndex (è¡¨ç¤ºé †)
- viewport (canvas è¡¨ç¤ºä½ç½®)
- sourcePosition, targetPosition (ã‚¨ãƒƒã‚¸æ¥ç¶šä½ç½®)

ã“ã‚Œã‚‰ã¯ã€Œè¦‹æ „ãˆã®å¤‰æ›´ã€ã§ã‚ã‚Šã€å‡¦ç†ã«å½±éŸ¿ã—ãªã„ãŸã‚ç„¡è¦–ã—ã¦ãã ã•ã„ã€‚

# é‡è¦ãªå·®åˆ†ï¼ˆå‡¦ç†ã«å½±éŸ¿ï¼‰
- nodes[].data.model.* (AI ãƒ¢ãƒ‡ãƒ«è¨­å®š)
- nodes[].data.prompt_template (ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå†…å®¹)
- nodes[].data.completion_params (ç”Ÿæˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿)
- edges[] ã®è¿½åŠ ãƒ»å‰Šé™¤ (ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼æ¥ç¶š)
- features.*.enabled (æ©Ÿèƒ½ ON/OFF)
- variables, environment_variables (å¤‰æ•°å®šç¾©)
- dependencies[] (ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ä¾å­˜)

# è§£ææ™‚ã®å¿…é ˆè¦ä»¶

1. **å…·ä½“çš„ãªå€¤ã‚’æŠ½å‡º**
   - å¤‰æ›´å‰ã®å€¤ï¼ˆBeforeï¼‰ã¨å¤‰æ›´å¾Œã®å€¤ï¼ˆAfterï¼‰ã‚’æ˜ç¤º
   - ä¾‹: "gemini-2.5-flash-preview-05-20 â†’ gemini-2.5-flash"

2. **å¤‰æ›´ç®‡æ‰€æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ**
   - åŒã˜å¤‰æ›´ãŒè¤‡æ•°ç®‡æ‰€ã«ã‚ã‚‹å ´åˆã¯ä»¶æ•°ã‚’æ˜è¨˜
   - ä¾‹: "10å€‹ã®LLMãƒãƒ¼ãƒ‰ã§å¤‰æ›´"

3. **çµ±è¨ˆæƒ…å ±ã‚’è¨ˆç®—**
   - å·®åˆ†ã®ç·è¡Œæ•°ï¼ˆ+ ã¨ - ã§å§‹ã¾ã‚‹è¡Œï¼‰
   - è¿½åŠ è¡Œæ•°ï¼ˆ+ ã§å§‹ã¾ã‚‹è¡Œï¼‰
   - å‰Šé™¤è¡Œæ•°ï¼ˆ- ã§å§‹ã¾ã‚‹è¡Œï¼‰
   - å½±éŸ¿ã‚’å—ã‘ã‚‹ãƒãƒ¼ãƒ‰æ•°ï¼ˆtitle ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®å¤‰æ›´ï¼‰
   - å½±éŸ¿ã‚’å—ã‘ã‚‹ã‚¨ãƒƒã‚¸æ•°ï¼ˆedges é…åˆ—ã®å¤‰æ›´ï¼‰

4. **ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œå‡º**
   - ä¸€æ‹¬å¤‰æ›´ã®å¯èƒ½æ€§ï¼ˆåŒã˜å¤‰æ›´ãŒè¤‡æ•°ç®‡æ‰€ï¼‰
   - é–¢é€£ã™ã‚‹å¤‰æ›´ã®ã‚°ãƒ«ãƒ¼ãƒ—åŒ–

5. **å…·ä½“çš„ãªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’æç¤º**
   - ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆå½¢å¼ã§"ä½•ã‚’ç¢ºèªã™ã¹ãã‹"
   - "ãªãœãã®ç¢ºèªãŒå¿…è¦ã‹"ã®ç†ç”±

# å‡ºåŠ›å½¢å¼
JSON å½¢å¼ã§ä»¥ä¸‹ã®æ§‹é€ ã‚’è¿”ã—ã¦ãã ã•ã„ï¼š

{
  "summary": "å¤‰æ›´å†…å®¹ã®è¦ç´„ï¼ˆæ—¥æœ¬èªã€1-2æ–‡ã€å…·ä½“çš„ãªæŠ€è¡“ç”¨èªã‚’å«ã‚ã‚‹ï¼‰",
  "statistics": {
    "total_diff_lines": 140,
    "added_lines": 95,
    "removed_lines": 45,
    "affected_nodes": 10,
    "affected_edges": 5
  },
  "changes": [
    {
      "type": "added|modified|removed",
      "impact": "high|medium|low",
      "area": "model|prompt|features|graph|config|dependencies|variables",
      "description": "å…·ä½“çš„ãªå¤‰æ›´å†…å®¹ï¼ˆBefore â†’ After ã®å½¢å¼ã§è¨˜è¼‰ï¼‰",
      "before_value": "å¤‰æ›´å‰ã®å…·ä½“çš„ãªå€¤ï¼ˆè©²å½“ã™ã‚‹å ´åˆï¼‰",
      "after_value": "å¤‰æ›´å¾Œã®å…·ä½“çš„ãªå€¤ï¼ˆè©²å½“ã™ã‚‹å ´åˆï¼‰",
      "count": 1,
      "action": "è¦ãƒ¬ãƒ“ãƒ¥ãƒ¼|ç¢ºèªæ¨å¥¨|ç„¡è¦–å¯"
    }
  ],
  "patterns": [
    {
      "description": "æ¤œå‡ºã•ã‚ŒãŸãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆä¾‹: ä¸€æ‹¬å¤‰æ›´ã€ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ç§»è¡Œï¼‰",
      "occurrences": 10
    }
  ],
  "overall_impact": "high|medium|low",
  "recommendation": {
    "immediate_actions": [
      "å³åº§ã«ç¢ºèªã™ã¹ãé …ç›®ï¼ˆãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆå½¢å¼ï¼‰"
    ],
    "review_questions": [
      "ãƒ¬ãƒ“ãƒ¥ãƒ¼æ™‚ã«ç¢ºèªã™ã¹ãè³ªå•"
    ]
  }
}
"""


def analyze_diff_with_llm(diff_text: str, model: str = "gpt-4o-mini") -> dict:
    """
    LLM ã§å·®åˆ†ã‚’è§£æ

    Args:
        diff_text: å·®åˆ†ãƒ†ã‚­ã‚¹ãƒˆ
        model: ä½¿ç”¨ã™ã‚‹ LLM ãƒ¢ãƒ‡ãƒ«

    Returns:
        è§£æçµæœã®è¾æ›¸
    """
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        raise ValueError("OPENAI_API_KEY environment variable is not set")

    client = OpenAI(api_key=api_key)

    print(f"ğŸ¤– Analyzing diff with {model}...")

    try:
        response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": SYSTEM_PROMPT},
                {"role": "user", "content": f"ä»¥ä¸‹ã® Dify DSL ã®å·®åˆ†ã‚’è§£æã—ã¦ãã ã•ã„ï¼š\n\n```diff\n{diff_text}\n```"}
            ],
            temperature=0.3,  # ä¸€è²«æ€§ã®ã‚ã‚‹å‡ºåŠ›ã®ãŸã‚ä½ã‚ã«è¨­å®š
            response_format={"type": "json_object"}
        )

        result = json.loads(response.choices[0].message.content)

        print(f"âœ… Analysis complete")
        print(f"ğŸ“Š Tokens used: {response.usage.total_tokens}")

        return result

    except Exception as e:
        print(f"âŒ Error during LLM analysis: {e}", file=sys.stderr)
        raise


def format_analysis_as_markdown(analysis: dict, diff_text: str) -> str:
    """
    è§£æçµæœã‚’ Markdown å½¢å¼ã«æ•´å½¢

    Args:
        analysis: LLM ã‹ã‚‰ã®è§£æçµæœ
        diff_text: å…ƒã®å·®åˆ†ãƒ†ã‚­ã‚¹ãƒˆ

    Returns:
        Markdown å½¢å¼ã®æ–‡å­—åˆ—
    """
    # Impact ã®ã‚¢ã‚¤ã‚³ãƒ³
    impact_icons = {
        "high": "ğŸ”´",
        "medium": "ğŸŸ¡",
        "low": "ğŸŸ¢"
    }

    # Type ã®ã‚¢ã‚¤ã‚³ãƒ³
    type_icons = {
        "added": "â•",
        "modified": "ğŸ“",
        "removed": "â–"
    }

    overall_icon = impact_icons.get(analysis.get("overall_impact", "low"), "âšª")

    md = f"""## ğŸ” Dify DSL å·®åˆ†è§£æãƒ¬ãƒãƒ¼ãƒˆ

### {overall_icon} ç·åˆå½±éŸ¿åº¦: {analysis.get('overall_impact', 'unknown').upper()}

**è¦ç´„**: {analysis.get('summary', 'å·®åˆ†ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ')}

---

"""

    # çµ±è¨ˆæƒ…å ±ã®è¿½åŠ 
    stats = analysis.get('statistics', {})
    if stats:
        md += f"""### ğŸ“Š å¤‰æ›´çµ±è¨ˆ

- **ç·å·®åˆ†è¡Œæ•°**: {stats.get('total_diff_lines', 'N/A')} è¡Œ
- **è¿½åŠ **: {stats.get('added_lines', 'N/A')} è¡Œ
- **å‰Šé™¤**: {stats.get('removed_lines', 'N/A')} è¡Œ
- **å½±éŸ¿ã‚’å—ã‘ã‚‹ãƒãƒ¼ãƒ‰æ•°**: {stats.get('affected_nodes', 'N/A')} å€‹
- **å½±éŸ¿ã‚’å—ã‘ã‚‹ã‚¨ãƒƒã‚¸æ•°**: {stats.get('affected_edges', 'N/A')} å€‹

---

"""

    md += """### ğŸ“‹ å¤‰æ›´ä¸€è¦§

"""

    changes = analysis.get('changes', [])
    if not changes:
        md += "_å¤‰æ›´ãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ_\n\n"
    else:
        for i, change in enumerate(changes, 1):
            type_icon = type_icons.get(change.get('type', ''), 'â“')
            impact_icon = impact_icons.get(change.get('impact', 'low'), 'âšª')

            md += f"""#### {i}. {type_icon} {change.get('type', 'unknown').upper()} - {change.get('area', 'unknown')}

- **å½±éŸ¿åº¦**: {impact_icon} {change.get('impact', 'unknown').upper()}
- **èª¬æ˜**: {change.get('description', 'èª¬æ˜ãªã—')}
"""

            # Before/After ã®å€¤ã‚’è¡¨ç¤º
            if change.get('before_value') or change.get('after_value'):
                md += "\n```diff\n"
                if change.get('before_value'):
                    md += f"- {change.get('before_value')}\n"
                if change.get('after_value'):
                    md += f"+ {change.get('after_value')}\n"
                md += "```\n"

            # å¤‰æ›´ä»¶æ•°ã‚’è¡¨ç¤º
            if change.get('count', 1) > 1:
                md += f"\n- **å¤‰æ›´ç®‡æ‰€æ•°**: {change.get('count')} ç®‡æ‰€\n"

            md += f"- **ã‚¢ã‚¯ã‚·ãƒ§ãƒ³**: {change.get('action', 'ç¢ºèªæ¨å¥¨')}\n\n"

    # ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æã®è¿½åŠ 
    patterns = analysis.get('patterns', [])
    if patterns:
        md += """---

### ğŸ” æ¤œå‡ºã•ã‚ŒãŸãƒ‘ã‚¿ãƒ¼ãƒ³

"""
        for pattern in patterns:
            md += f"- **{pattern.get('description', 'ä¸æ˜ãªãƒ‘ã‚¿ãƒ¼ãƒ³')}**: {pattern.get('occurrences', 0)} ç®‡æ‰€\n"
        md += "\n"

    md += """---

### ğŸ’¡ æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³

"""

    recommendation = analysis.get('recommendation', {})
    if isinstance(recommendation, dict):
        # æ–°ã—ã„æ§‹é€ åŒ–ã•ã‚ŒãŸæ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
        immediate_actions = recommendation.get('immediate_actions', [])
        if immediate_actions:
            md += "#### ğŸš¨ å³åº§ã«ç¢ºèªã™ã¹ãé …ç›®\n\n"
            for action in immediate_actions:
                md += f"- [ ] {action}\n"
            md += "\n"

        review_questions = recommendation.get('review_questions', [])
        if review_questions:
            md += "#### ğŸ“ ãƒ¬ãƒ“ãƒ¥ãƒ¼æ™‚ã®ç¢ºèªäº‹é …\n\n"
            for question in review_questions:
                md += f"- {question}\n"
            md += "\n"
    else:
        # å¤ã„å½¢å¼ï¼ˆæ–‡å­—åˆ—ï¼‰ã¸ã®å¾Œæ–¹äº’æ›æ€§
        md += f"{recommendation}\n\n"

    md += f"""---

<details>
<summary>ğŸ“„ å…ƒã®å·®åˆ†ã‚’è¡¨ç¤º</summary>

```diff
{diff_text}
```

</details>

---

_ğŸ¤– ã“ã®è§£æã¯ LLM ã«ã‚ˆã‚Šè‡ªå‹•ç”Ÿæˆã•ã‚Œã¾ã—ãŸ_
"""

    return md


def main():
    if len(sys.argv) != 2:
        print(f"Usage: {sys.argv[0]} <diff.txt>", file=sys.stderr)
        print(f"\nExample:", file=sys.stderr)
        print(f"  {sys.argv[0]} diff.txt", file=sys.stderr)
        sys.exit(1)

    diff_path = Path(sys.argv[1])

    # å·®åˆ†ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
    if not diff_path.exists():
        print(f"âŒ Error: Diff file not found: {diff_path}", file=sys.stderr)
        sys.exit(1)

    # å·®åˆ†ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿
    try:
        with diff_path.open('r', encoding='utf-8') as f:
            diff_text = f.read()
    except Exception as e:
        print(f"âŒ Error: Failed to read diff file: {e}", file=sys.stderr)
        sys.exit(1)

    # ç©ºã®å·®åˆ†ã‚’ãƒã‚§ãƒƒã‚¯
    if not diff_text.strip():
        print("â„¹ï¸  No diff detected (empty file)")
        result = {
            "summary": "å·®åˆ†ãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ",
            "changes": [],
            "overall_impact": "low",
            "recommendation": "å¤‰æ›´ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚"
        }
        print(json.dumps(result, ensure_ascii=False, indent=2))
        sys.exit(0)

    # LLM ã§è§£æ
    model = os.getenv("LLM_MODEL", "gpt-4o-mini")

    try:
        analysis = analyze_diff_with_llm(diff_text, model)
    except Exception as e:
        print(f"âŒ Fatal error: {e}", file=sys.stderr)
        sys.exit(1)

    # JSON å‡ºåŠ›
    print("\n" + "="*60)
    print("JSON Output:")
    print("="*60)
    print(json.dumps(analysis, ensure_ascii=False, indent=2))

    # Markdown å‡ºåŠ›
    markdown = format_analysis_as_markdown(analysis, diff_text)
    output_path = diff_path.parent / f"{diff_path.stem}_analysis.md"

    try:
        with output_path.open('w', encoding='utf-8') as f:
            f.write(markdown)
        print(f"\nâœ… Markdown report saved to: {output_path}")
    except Exception as e:
        print(f"âš ï¸  Warning: Failed to save markdown: {e}", file=sys.stderr)

    # GitHub Actions ã® output ã«è¨­å®šã™ã‚‹ãŸã‚ã®æƒ…å ±ã‚’å‡ºåŠ›
    if os.getenv("GITHUB_OUTPUT"):
        try:
            with open(os.getenv("GITHUB_OUTPUT"), "a") as f:
                f.write(f"analysis_json<<EOF\n{json.dumps(analysis, ensure_ascii=False)}\nEOF\n")
                f.write(f"overall_impact={analysis.get('overall_impact', 'low')}\n")
        except Exception as e:
            print(f"âš ï¸  Warning: Failed to write to GITHUB_OUTPUT: {e}", file=sys.stderr)


if __name__ == '__main__':
    main()
