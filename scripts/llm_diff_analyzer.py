#!/usr/bin/env python3
"""
LLM ã«ã‚ˆã‚‹ Dify DSL å·®åˆ†è§£æã‚¹ã‚¯ãƒªãƒ—ãƒˆ

å·®åˆ†ã‚’ LLM ã«æ¸¡ã—ã¦é‡è¦åº¦ã‚’åˆ¤å®šã—ã€äººé–“ãŒèª­ã¿ã‚„ã™ã„èª¬æ˜ã‚’ç”Ÿæˆã—ã¾ã™ã€‚

Usage:
    python scripts/llm_diff_analyzer.py <diff.txt> [--before <old.yml> --after <new.yml>]

Environment Variables:
    OPENAI_API_KEY: OpenAI API ã‚­ãƒ¼ï¼ˆå¿…é ˆï¼‰
    LLM_MODEL: ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: gpt-5.1ï¼‰
"""

import argparse
import os
import re
import sys
import json
from pathlib import Path
from typing import Optional

try:
    from openai import OpenAI
except ImportError:
    print("âŒ Error: openai package is not installed.", file=sys.stderr)
    print("Install it with: pip install openai", file=sys.stderr)
    sys.exit(1)

try:
    from ruamel.yaml import YAML
except ImportError:
    print("âŒ Error: ruamel.yaml package is not installed.", file=sys.stderr)
    print("Install it with: pip install ruamel.yaml", file=sys.stderr)
    sys.exit(1)


SYSTEM_PROMPT = """ã‚ãªãŸã¯ Dify DSL ã®å·®åˆ†ã‚’è§£æã™ã‚‹å°‚é–€å®¶ã§ã™ã€‚
å¤‰æ›´å†…å®¹ã‚’äº‹å®Ÿãƒ™ãƒ¼ã‚¹ã§åˆ†ã‹ã‚Šã‚„ã™ãæ•´ç†ã—ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒ YAML diff ã‚’èª­ã‚€å‰ã«æ¦‚è¦ã¨ãƒ¬ãƒ“ãƒ¥ãƒ¼è¦³ç‚¹ã®å¤‰æ›´ç‚¹ã‚’æŠŠæ¡ã§ãã‚‹ã‚ˆã†ã«ã—ã¦ãã ã•ã„ã€‚

# ç„¡è¦–ã™ã¹ãå·®åˆ†ï¼ˆUI ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ï¼‰
- position, positionAbsolute (ãƒãƒ¼ãƒ‰åº§æ¨™)
- width, height (ãƒãƒ¼ãƒ‰ã‚µã‚¤ã‚º)
- selected (UI é¸æŠçŠ¶æ…‹)
- zIndex (è¡¨ç¤ºé †)
- viewport (canvas è¡¨ç¤ºä½ç½®)
- sourcePosition, targetPosition (ã‚¨ãƒƒã‚¸æ¥ç¶šä½ç½®)

ã“ã‚Œã‚‰ã¯ã€Œè¦‹æ „ãˆã®å¤‰æ›´ã€ã§ã‚ã‚Šã€å‡¦ç†ã«å½±éŸ¿ã—ãªã„ãŸã‚ç„¡è¦–ã—ã¦ãã ã•ã„ã€‚

# é‡è¦ãªå·®åˆ†ï¼ˆå‡¦ç†ã«å½±éŸ¿ï¼‰
- workflow.graph.nodes[].data.model.* (AI ãƒ¢ãƒ‡ãƒ«è¨­å®š)
- workflow.graph.nodes[].data.prompt_template (ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå†…å®¹)
- workflow.graph.nodes[].data.completion_params (ç”Ÿæˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿)
- workflow.graph.edges[] (ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼æ¥ç¶š)
- workflow.features.*.enabled (æ©Ÿèƒ½ ON/OFF)
- workflow.conversation_variables, workflow.environment_variables (å¤‰æ•°å®šç¾©)
- dependencies[] (ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ä¾å­˜)

# è§£ææ™‚ã®å¿…é ˆè¦ä»¶

1. **YAMLãƒ‘ã‚¹ã‚’æ˜è¨˜**
   - å¤‰æ›´ç®‡æ‰€ã‚’YAMLãƒ‘ã‚¹è¡¨è¨˜ã§ç¤ºã™
     - å˜ä¸€å¤‰æ›´: `workflow.graph.edges[0]`, `workflow.graph.nodes[2].data.type`
     - ã¾ã¨ã‚å¤‰æ›´: `workflow.graph.nodes[].data.model.name` ã®ã‚ˆã†ã«é…åˆ—ã‚’ã¾ã¨ã‚ã¦ç¤ºã™
   - å˜ä¸€å¤‰æ›´ã§ã¯é…åˆ—ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¯å®Ÿéš›ã®ä½ç½®ã‚’ç¤ºã™ï¼ˆ0å§‹ã¾ã‚Šï¼‰
   - ãƒã‚¹ãƒˆã—ãŸæ§‹é€ ã‚‚æ˜ç¢ºã«è¡¨ç¾

2. **å·®åˆ†ã®è¡Œç•ªå·ã‚’æŠ½å‡º**
   - diff ã® @@ è¡Œã‹ã‚‰è¡Œç•ªå·æƒ…å ±ã‚’å–å¾—
   - å„å¤‰æ›´ãŒãƒ•ã‚¡ã‚¤ãƒ«ã®ä½•è¡Œç›®ä»˜è¿‘ã«ã‚ã‚‹ã‹ã‚’æ˜è¨˜
   - ä¾‹: "L142-L145" ã®ã‚ˆã†ãªå½¢å¼ã§è¡¨ç¤º

3. **å…·ä½“çš„ãªå€¤ã‚’æŠ½å‡º**
   - `changes.before_value` ã¨ `changes.after_value` ã«å…·ä½“å€¤ã‚’å…¥ã‚Œã‚‹
   - `changes.description` ã§ã¯å½±éŸ¿ãŒä¼ã‚ã‚‹çŸ­ã„èª¬æ˜ã‚’æ·»ãˆã‚‹

4. **å¤‰æ›´ç®‡æ‰€æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ**
   - åŒæ§˜ã®å¤‰æ›´ãŒè¤‡æ•°ç®‡æ‰€ã«ã‚ã‚‹å ´åˆã¯ `count` ã§ä»¶æ•°ã‚’æ˜è¨˜

5. **ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”¨ã®è¦ç‚¹ã‚’ä½œæˆ**
   - è¦ç´„ã‚ˆã‚Šè©³ç´°ã§ã€å¤‰æ›´ä¸€è¦§ã‚ˆã‚ŠæŠ½è±¡åº¦ã‚’ä¸Šã’ã‚‹
   - å¤‰æ›´ç‚¹ã‚’ 3ã€œ10 ä»¶ã®ç®‡æ¡æ›¸ãã§æ•´ç†
   - å¤‰æ›´ã®å¯¾è±¡ç¯„å›²ï¼ˆYAML ãƒ‘ã‚¹ã®ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ç­‰ï¼‰ã‚’æ˜è¨˜
   - å˜ãªã‚‹å·®åˆ†åˆ—æŒ™ã¯é¿ã‘ã€PR ãƒ¬ãƒ“ãƒ¥ãƒ¼ã§è«–ç‚¹ã«ãªã‚‹å˜ä½ã«ã¾ã¨ã‚ã‚‹

6. **å¤‰æ›´ä¸€è¦§ã¯é©åº¦ã«ã¾ã¨ã‚ã‚‹**
   - 1è¡Œå˜ä½ã®ç¾…åˆ—ã¯é¿ã‘ã€åŒç¨®ã®å¤‰æ›´ã¯1é …ç›®ã«ã¾ã¨ã‚ã‚‹

# å‡ºåŠ›å½¢å¼
JSON å½¢å¼ã§ä»¥ä¸‹ã®æ§‹é€ ã‚’è¿”ã—ã¦ãã ã•ã„ï¼š

âš ï¸ **é‡è¦**:
- ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚„æ¨å¥¨äº‹é …ã¯å«ã‚ãªã„ã§ãã ã•ã„ã€‚äº‹å®Ÿã®ã¿ã‚’è¨˜è¼‰ã—ã¦ãã ã•ã„ã€‚
- yaml_path ã¯å…·ä½“çš„ãªéšå±¤æ§‹é€ ã‚’ç¤ºã—ã¦ãã ã•ã„ï¼ˆä¾‹: workflow.graph.nodes[0].data.model.nameï¼‰

{
  "summary": "å¤‰æ›´å†…å®¹ã®è¦ç´„ï¼ˆæ—¥æœ¬èªã€1-2æ–‡ã€å…·ä½“çš„ãªæŠ€è¡“ç”¨èªã‚’å«ã‚ã‚‹ï¼‰",
  "review_points": [
    {
      "title": "ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”¨ã®å¤‰æ›´ç‚¹ï¼ˆçŸ­ãï¼‰",
      "details": "å¤‰æ›´ã®ä¸­èº«ã‚’1-2æ–‡ã§å…·ä½“åŒ–ï¼ˆBefore/Afterã‚„å½±éŸ¿ç¯„å›²ãŒåˆ†ã‹ã‚‹ã‚ˆã†ã«ï¼‰",
      "scope": "ä¸»ãªå¯¾è±¡ç¯„å›²ã® YAML ãƒ‘ã‚¹ï¼ˆãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹å¯ï¼‰",
      "count": 1
    }
  ],
  "changes": [
    {
      "type": "added|modified|removed",
      "yaml_path": "workflow.graph.nodes[0].data.model.name",
      "location": "å¤‰æ›´ç®‡æ‰€ã®è¡Œç•ªå·ï¼ˆä¾‹: L142-L145ï¼‰",
      "description": "å…·ä½“çš„ãªå¤‰æ›´å†…å®¹ï¼ˆçŸ­ã„èª¬æ˜ï¼‰",
      "before_value": "å¤‰æ›´å‰ã®å…·ä½“çš„ãªå€¤ï¼ˆè©²å½“ã™ã‚‹å ´åˆï¼‰",
      "after_value": "å¤‰æ›´å¾Œã®å…·ä½“çš„ãªå€¤ï¼ˆè©²å½“ã™ã‚‹å ´åˆï¼‰",
      "count": 1
    }
  ]
}
"""

IGNORED_KEYS = {
    "position",
    "positionAbsolute",
    "width",
    "height",
    "selected",
    "zIndex",
    "viewport",
    "sourcePosition",
    "targetPosition",
}


def strip_ignored(value):
    if isinstance(value, dict):
        return {
            key: strip_ignored(val)
            for key, val in value.items()
            if key not in IGNORED_KEYS
        }
    if isinstance(value, list):
        return [strip_ignored(item) for item in value]
    return value


def load_yaml(path: Path):
    yaml = YAML(typ="safe")
    with path.open('r', encoding='utf-8') as f:
        return yaml.load(f) or {}


def get_graph_data(data):
    workflow = data.get("workflow", {}) if isinstance(data, dict) else {}
    graph = workflow.get("graph", {}) if isinstance(workflow, dict) else {}
    nodes = graph.get("nodes", [])
    edges = graph.get("edges", [])
    return nodes if isinstance(nodes, list) else [], edges if isinstance(edges, list) else []


def node_label(node_id: str, node: dict) -> str:
    data = node.get("data", {}) if isinstance(node, dict) else {}
    title = data.get("title")
    node_type = data.get("type")
    if title and node_type:
        label = f"{title}<br/>({node_type})"
    elif title:
        label = str(title)
    elif node_type:
        label = f"{node_type}"
    else:
        label = str(node_id)
    return label.replace('"', "'").strip()


def mermaid_id(raw_id: str) -> str:
    return "n_" + re.sub(r"[^A-Za-z0-9_]", "_", str(raw_id))


def edge_key(edge: dict) -> str:
    if not isinstance(edge, dict):
        return ""
    edge_id = edge.get("id")
    if edge_id:
        return str(edge_id)
    source = edge.get("source", "")
    target = edge.get("target", "")
    return f"{source}->{target}"


def build_change_diagram(before_data: dict, after_data: dict) -> Optional[str]:
    old_nodes_list, old_edges_list = get_graph_data(before_data)
    new_nodes_list, new_edges_list = get_graph_data(after_data)

    old_nodes = {str(n.get("id")): n for n in old_nodes_list if isinstance(n, dict) and n.get("id") is not None}
    new_nodes = {str(n.get("id")): n for n in new_nodes_list if isinstance(n, dict) and n.get("id") is not None}

    old_edges = {edge_key(e): e for e in old_edges_list if edge_key(e)}
    new_edges = {edge_key(e): e for e in new_edges_list if edge_key(e)}

    old_node_ids = set(old_nodes.keys())
    new_node_ids = set(new_nodes.keys())

    added_nodes = new_node_ids - old_node_ids
    removed_nodes = old_node_ids - new_node_ids
    common_nodes = old_node_ids & new_node_ids

    modified_nodes = {
        node_id
        for node_id in common_nodes
        if strip_ignored(old_nodes.get(node_id)) != strip_ignored(new_nodes.get(node_id))
    }

    old_edge_keys = set(old_edges.keys())
    new_edge_keys = set(new_edges.keys())

    added_edges = new_edge_keys - old_edge_keys
    removed_edges = old_edge_keys - new_edge_keys
    common_edges = old_edge_keys & new_edge_keys

    modified_edges = {
        edge_id
        for edge_id in common_edges
        if strip_ignored(old_edges.get(edge_id)) != strip_ignored(new_edges.get(edge_id))
    }

    if not (added_nodes or removed_nodes or modified_nodes or added_edges or removed_edges or modified_edges):
        return None

    context_edges = set()
    if added_nodes or modified_nodes:
        for edge in new_edges_list:
            if not isinstance(edge, dict):
                continue
            source = str(edge.get("source", ""))
            target = str(edge.get("target", ""))
            if source in added_nodes or source in modified_nodes or target in added_nodes or target in modified_nodes:
                key = edge_key(edge)
                if key:
                    context_edges.add(key)
    if removed_nodes:
        for edge in old_edges_list:
            if not isinstance(edge, dict):
                continue
            source = str(edge.get("source", ""))
            target = str(edge.get("target", ""))
            if source in removed_nodes or target in removed_nodes:
                key = edge_key(edge)
                if key:
                    context_edges.add(key)

    edges_to_draw = set().union(added_edges, removed_edges, modified_edges, context_edges)
    edges_to_draw_list = []
    for key in sorted(edges_to_draw):
        edge = old_edges.get(key) if key in removed_edges else new_edges.get(key) or old_edges.get(key)
        if edge:
            edges_to_draw_list.append((key, edge))

    nodes_to_draw = set(added_nodes) | set(removed_nodes) | set(modified_nodes)
    for _, edge in edges_to_draw_list:
        source = edge.get("source")
        target = edge.get("target")
        if source is not None:
            nodes_to_draw.add(str(source))
        if target is not None:
            nodes_to_draw.add(str(target))

    if not nodes_to_draw:
        return None

    node_lines = []
    for node_id in sorted(nodes_to_draw):
        node = new_nodes.get(node_id) or old_nodes.get(node_id)
        if not node:
            continue
        label = node_label(node_id, node)
        node_class = ""
        if node_id in added_nodes:
            node_class = "added"
        elif node_id in removed_nodes:
            node_class = "removed"
        elif node_id in modified_nodes:
            node_class = "modified"
        line = f'{mermaid_id(node_id)}["{label}"]'
        if node_class:
            line += f":::{node_class}"
        node_lines.append(line)

    edge_lines = []
    link_styles = []
    edge_index = 0
    for key, edge in edges_to_draw_list:
        source = str(edge.get("source", ""))
        target = str(edge.get("target", ""))
        if not source or not target:
            continue
        edge_lines.append(f"{mermaid_id(source)} --> {mermaid_id(target)}")
        style_class = None
        if key in added_edges:
            style_class = "added"
        elif key in removed_edges:
            style_class = "removed"
        elif key in modified_edges:
            style_class = "modified"
        if style_class:
            link_styles.append((edge_index, style_class))
        edge_index += 1

    diagram_lines = [
        "flowchart LR",
        "classDef added fill:#D1FAE5,stroke:#10B981,color:#065F46;",
        "classDef removed fill:#FEE2E2,stroke:#EF4444,color:#7F1D1D,stroke-dasharray: 5 5;",
        "classDef modified fill:#FEF3C7,stroke:#F59E0B,color:#78350F;",
    ]
    diagram_lines.extend(node_lines)
    diagram_lines.extend(edge_lines)

    for index, style_class in link_styles:
        if style_class == "added":
            diagram_lines.append(f"linkStyle {index} stroke:#10B981,stroke-width:2px;")
        elif style_class == "removed":
            diagram_lines.append(
                f"linkStyle {index} stroke:#EF4444,stroke-width:2px,stroke-dasharray: 5 5;"
            )
        elif style_class == "modified":
            diagram_lines.append(f"linkStyle {index} stroke:#F59E0B,stroke-width:2px;")

    return "\n".join(diagram_lines)


def analyze_diff_with_llm(diff_text: str, model: str = "gpt-5.1") -> dict:
    """
    LLM ã§å·®åˆ†ã‚’è§£æ

    Args:
        diff_text: å·®åˆ†ãƒ†ã‚­ã‚¹ãƒˆ
        model: ä½¿ç”¨ã™ã‚‹ LLM ãƒ¢ãƒ‡ãƒ«

    Returns:
        è§£æçµæœã®è¾æ›¸
    """
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        raise ValueError("OPENAI_API_KEY environment variable is not set")

    client = OpenAI(api_key=api_key)

    print(f"ğŸ¤– Analyzing diff with {model}...")

    try:
        response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": SYSTEM_PROMPT},
                {"role": "user", "content": f"ä»¥ä¸‹ã® Dify DSL ã®å·®åˆ†ã‚’è§£æã—ã¦ãã ã•ã„ï¼š\n\n```diff\n{diff_text}\n```"}
            ],
            temperature=0.3,  # ä¸€è²«æ€§ã®ã‚ã‚‹å‡ºåŠ›ã®ãŸã‚ä½ã‚ã«è¨­å®š
            response_format={"type": "json_object"}
        )

        result = json.loads(response.choices[0].message.content)

        print(f"âœ… Analysis complete")
        print(f"ğŸ“Š Tokens used: {response.usage.total_tokens}")

        return result

    except Exception as e:
        print(f"âŒ Error during LLM analysis: {e}", file=sys.stderr)
        raise


def format_analysis_as_markdown(analysis: dict, diagram: Optional[str] = None) -> str:
    """
    è§£æçµæœã‚’ Markdown å½¢å¼ã«æ•´å½¢

    Args:
        analysis: LLM ã‹ã‚‰ã®è§£æçµæœ

    Returns:
        Markdown å½¢å¼ã®æ–‡å­—åˆ—
    """
    # Type ã®ã‚¢ã‚¤ã‚³ãƒ³
    type_icons = {
        "added": "â•",
        "modified": "ğŸ“",
        "removed": "â–"
    }

    md = f"""## ğŸ” Dify DSL å·®åˆ†è§£æãƒ¬ãƒãƒ¼ãƒˆ

**è¦ç´„**: {analysis.get('summary', 'å·®åˆ†ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ')}

---

"""

    review_points = analysis.get('review_points', [])
    if review_points:
        md += "### ğŸ§­ å¤‰æ›´ã®è¦ç‚¹\n\n"
        for point in review_points:
            title = point.get('title', 'å¤‰æ›´ç‚¹')
            details = point.get('details')
            scope = point.get('scope')
            count = point.get('count')

            line = f"- **{title}**"
            if scope:
                line += f" (`{scope}`)"
            if isinstance(count, int) and count > 1:
                line += f" Ã—{count}"
            if details:
                line += f": {details}"
            md += f"{line}\n"
        md += "\n---\n\n"

    if diagram:
        md += "### ğŸ—ºï¸ å¤‰æ›´ãƒ•ãƒ­ãƒ¼å›³\n\n"
        md += "```mermaid\n"
        md += diagram
        md += "\n```\n\n---\n\n"

    md += """<details>
<summary>ğŸ“‹ å¤‰æ›´ä¸€è¦§ã‚’è¡¨ç¤º</summary>

### ğŸ“‹ å¤‰æ›´ä¸€è¦§

"""

    changes = analysis.get('changes', [])
    if not changes:
        md += "_å¤‰æ›´ãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ_\n\n"
    else:
        for i, change in enumerate(changes, 1):
            type_icon = type_icons.get(change.get('type', ''), 'â“')
            yaml_path = change.get('yaml_path', change.get('area', 'unknown'))  # å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ area ã‚‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯

            md += f"""#### {i}. {type_icon} {change.get('type', 'unknown').upper()} - `{yaml_path}`

"""

            # è¡Œç•ªå·ã®è¡¨ç¤º
            if change.get('location'):
                md += f"**è¡Œç•ªå·**: {change.get('location')}\n\n"

            md += f"{change.get('description', 'èª¬æ˜ãªã—')}\n"

            # Before/After ã®å€¤ã‚’è¡¨ç¤º
            if change.get('before_value') or change.get('after_value'):
                md += "\n```diff\n"
                if change.get('before_value'):
                    md += f"- {change.get('before_value')}\n"
                if change.get('after_value'):
                    md += f"+ {change.get('after_value')}\n"
                md += "```\n"

            # å¤‰æ›´ä»¶æ•°ã‚’è¡¨ç¤º
            if change.get('count', 1) > 1:
                md += f"\n- **å¤‰æ›´ç®‡æ‰€æ•°**: {change.get('count')} ç®‡æ‰€\n"

            md += "\n"

    md += "</details>\n\n"

    md += """---

_ğŸ¤– ã“ã®è§£æã¯ LLM ã«ã‚ˆã‚Šè‡ªå‹•ç”Ÿæˆã•ã‚Œã¾ã—ãŸ_
"""

    return md


def main():
    parser = argparse.ArgumentParser(description="Analyze Dify DSL diff with LLM")
    parser.add_argument("diff_path", help="Path to diff file")
    parser.add_argument("--before", help="Path to old Dify DSL YAML")
    parser.add_argument("--after", help="Path to new Dify DSL YAML")
    args = parser.parse_args()

    diff_path = Path(args.diff_path)
    before_path = Path(args.before) if args.before else None
    after_path = Path(args.after) if args.after else None

    # å·®åˆ†ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
    if not diff_path.exists():
        print(f"âŒ Error: Diff file not found: {diff_path}", file=sys.stderr)
        sys.exit(1)

    # å·®åˆ†ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿
    try:
        with diff_path.open('r', encoding='utf-8') as f:
            diff_text = f.read()
    except Exception as e:
        print(f"âŒ Error: Failed to read diff file: {e}", file=sys.stderr)
        sys.exit(1)

    # ç©ºã®å·®åˆ†ã‚’ãƒã‚§ãƒƒã‚¯
    if not diff_text.strip():
        print("â„¹ï¸  No diff detected (empty file)")
        result = {
            "summary": "å·®åˆ†ãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ",
            "changes": [],
            "overall_impact": "low"
        }
        print(json.dumps(result, ensure_ascii=False, indent=2))
        sys.exit(0)

    # LLM ã§è§£æ
    model = os.getenv("LLM_MODEL", "gpt-5.1")

    try:
        analysis = analyze_diff_with_llm(diff_text, model)
    except Exception as e:
        print(f"âŒ Fatal error: {e}", file=sys.stderr)
        sys.exit(1)

    # JSON å‡ºåŠ›
    print("\n" + "="*60)
    print("JSON Output:")
    print("="*60)
    print(json.dumps(analysis, ensure_ascii=False, indent=2))

    diagram = None
    if before_path or after_path:
        if not (before_path and after_path):
            print("âš ï¸  Warning: --before ã¨ --after ã®ä¸¡æ–¹ãŒå¿…è¦ã§ã™ã€‚å›³ã®ç”Ÿæˆã¯ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
        elif not before_path.exists():
            print(f"âš ï¸  Warning: before file not found: {before_path}")
        elif not after_path.exists():
            print(f"âš ï¸  Warning: after file not found: {after_path}")
        else:
            try:
                before_data = load_yaml(before_path)
                after_data = load_yaml(after_path)
                diagram = build_change_diagram(before_data, after_data)
                if diagram:
                    print("ğŸ—ºï¸  Diagram generated")
            except Exception as e:
                print(f"âš ï¸  Warning: Failed to generate diagram: {e}", file=sys.stderr)

    # Markdown å‡ºåŠ›
    markdown = format_analysis_as_markdown(analysis, diagram)
    output_path = diff_path.parent / f"{diff_path.stem}_analysis.md"

    try:
        with output_path.open('w', encoding='utf-8') as f:
            f.write(markdown)
        print(f"\nâœ… Markdown report saved to: {output_path}")
    except Exception as e:
        print(f"âš ï¸  Warning: Failed to save markdown: {e}", file=sys.stderr)

    # GitHub Actions ã® output ã«è¨­å®šã™ã‚‹ãŸã‚ã®æƒ…å ±ã‚’å‡ºåŠ›
    if os.getenv("GITHUB_OUTPUT"):
        try:
            with open(os.getenv("GITHUB_OUTPUT"), "a") as f:
                f.write(f"analysis_json<<EOF\n{json.dumps(analysis, ensure_ascii=False)}\nEOF\n")
                f.write(f"overall_impact={analysis.get('overall_impact', 'low')}\n")
        except Exception as e:
            print(f"âš ï¸  Warning: Failed to write to GITHUB_OUTPUT: {e}", file=sys.stderr)


if __name__ == '__main__':
    main()

# trigger
