#!/usr/bin/env python3
"""
LLM ã«ã‚ˆã‚‹ Dify DSL å·®åˆ†è§£æã‚¹ã‚¯ãƒªãƒ—ãƒˆ

å·®åˆ†ã‚’ LLM ã«æ¸¡ã—ã¦é‡è¦åº¦ã‚’åˆ¤å®šã—ã€äººé–“ãŒèª­ã¿ã‚„ã™ã„èª¬æ˜ã‚’ç”Ÿæˆã—ã¾ã™ã€‚

Usage:
    python scripts/llm_diff_analyzer.py <diff.txt>

Environment Variables:
    OPENAI_API_KEY: OpenAI API ã‚­ãƒ¼ï¼ˆå¿…é ˆï¼‰
    LLM_MODEL: ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: gpt-4o-miniï¼‰
"""

import os
import sys
import json
from pathlib import Path

try:
    from openai import OpenAI
except ImportError:
    print("âŒ Error: openai package is not installed.", file=sys.stderr)
    print("Install it with: pip install openai", file=sys.stderr)
    sys.exit(1)


SYSTEM_PROMPT = """ã‚ãªãŸã¯ Dify DSL ã®å·®åˆ†ã‚’è§£æã™ã‚‹å°‚é–€å®¶ã§ã™ã€‚
å¤‰æ›´å†…å®¹ã‚’äº‹å®Ÿãƒ™ãƒ¼ã‚¹ã§åˆ†ã‹ã‚Šã‚„ã™ãæ•´ç†ã—ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒ YAML diff ã‚’èª­ã‚€å‰ã«æ¦‚è¦ã‚’æŠŠæ¡ã§ãã‚‹ã‚ˆã†ã«ã—ã¦ãã ã•ã„ã€‚

# ç„¡è¦–ã™ã¹ãå·®åˆ†ï¼ˆUI ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ï¼‰
- position, positionAbsolute (ãƒãƒ¼ãƒ‰åº§æ¨™)
- width, height (ãƒãƒ¼ãƒ‰ã‚µã‚¤ã‚º)
- selected (UI é¸æŠçŠ¶æ…‹)
- zIndex (è¡¨ç¤ºé †)
- viewport (canvas è¡¨ç¤ºä½ç½®)
- sourcePosition, targetPosition (ã‚¨ãƒƒã‚¸æ¥ç¶šä½ç½®)

ã“ã‚Œã‚‰ã¯ã€Œè¦‹æ „ãˆã®å¤‰æ›´ã€ã§ã‚ã‚Šã€å‡¦ç†ã«å½±éŸ¿ã—ãªã„ãŸã‚ç„¡è¦–ã—ã¦ãã ã•ã„ã€‚

# é‡è¦ãªå·®åˆ†ï¼ˆå‡¦ç†ã«å½±éŸ¿ï¼‰
- workflow.graph.nodes[].data.model.* (AI ãƒ¢ãƒ‡ãƒ«è¨­å®š)
- workflow.graph.nodes[].data.prompt_template (ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå†…å®¹)
- workflow.graph.nodes[].data.completion_params (ç”Ÿæˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿)
- workflow.graph.edges[] (ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼æ¥ç¶š)
- workflow.features.*.enabled (æ©Ÿèƒ½ ON/OFF)
- workflow.conversation_variables, workflow.environment_variables (å¤‰æ•°å®šç¾©)
- dependencies[] (ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ä¾å­˜)

# è§£ææ™‚ã®å¿…é ˆè¦ä»¶

1. **YAMLãƒ‘ã‚¹ã‚’æ˜è¨˜**
   - å¤‰æ›´ç®‡æ‰€ã‚’YAMLãƒ‘ã‚¹è¡¨è¨˜ã§ç¤ºã™ï¼ˆä¾‹: `workflow.graph.edges[0]`, `workflow.graph.nodes[2].data.type`ï¼‰
   - é…åˆ—ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¯å®Ÿéš›ã®ä½ç½®ã‚’ç¤ºã™ï¼ˆ0å§‹ã¾ã‚Šï¼‰
   - ãƒã‚¹ãƒˆã—ãŸæ§‹é€ ã‚‚æ˜ç¢ºã«è¡¨ç¾

2. **å·®åˆ†ã®è¡Œç•ªå·ã‚’æŠ½å‡º**
   - diff ã® @@ è¡Œã‹ã‚‰è¡Œç•ªå·æƒ…å ±ã‚’å–å¾—
   - å„å¤‰æ›´ãŒãƒ•ã‚¡ã‚¤ãƒ«ã®ä½•è¡Œç›®ä»˜è¿‘ã«ã‚ã‚‹ã‹ã‚’æ˜è¨˜
   - ä¾‹: "L142-L145" ã®ã‚ˆã†ãªå½¢å¼ã§è¡¨ç¤º

3. **å…·ä½“çš„ãªå€¤ã‚’æŠ½å‡º**
   - å¤‰æ›´å‰ã®å€¤ï¼ˆBeforeï¼‰ã¨å¤‰æ›´å¾Œã®å€¤ï¼ˆAfterï¼‰ã‚’æ˜ç¤º
   - ä¾‹: "gemini-2.5-flash-preview-05-20 â†’ gemini-2.5-flash"

4. **å¤‰æ›´ç®‡æ‰€æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ**
   - åŒã˜å¤‰æ›´ãŒè¤‡æ•°ç®‡æ‰€ã«ã‚ã‚‹å ´åˆã¯ä»¶æ•°ã‚’æ˜è¨˜
   - ä¾‹: "10å€‹ã®LLMãƒãƒ¼ãƒ‰ã§å¤‰æ›´"

5. **çµ±è¨ˆæƒ…å ±ã‚’è¨ˆç®—**
   - å·®åˆ†ã®ç·è¡Œæ•°ï¼ˆ+ ã¨ - ã§å§‹ã¾ã‚‹è¡Œã‚’å®Ÿéš›ã«æ•°ãˆã‚‹ï¼‰
   - è¿½åŠ è¡Œæ•°ï¼ˆ+ ã§å§‹ã¾ã‚‹è¡Œã‚’å®Ÿéš›ã«æ•°ãˆã‚‹ï¼‰
   - å‰Šé™¤è¡Œæ•°ï¼ˆ- ã§å§‹ã¾ã‚‹è¡Œã‚’å®Ÿéš›ã«æ•°ãˆã‚‹ï¼‰
   - å½±éŸ¿ã‚’å—ã‘ã‚‹ãƒãƒ¼ãƒ‰æ•°ï¼ˆtitle ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®å¤‰æ›´ã‚’å®Ÿéš›ã«æ•°ãˆã‚‹ï¼‰
   - å½±éŸ¿ã‚’å—ã‘ã‚‹ã‚¨ãƒƒã‚¸æ•°ï¼ˆedges é…åˆ—ã®å¤‰æ›´ã‚’å®Ÿéš›ã«æ•°ãˆã‚‹ï¼‰
   - âš ï¸ ä¾‹ã®æ•°å€¤ã‚’ãã®ã¾ã¾ä½¿ã‚ãªã„ã§ãã ã•ã„ã€‚å¿…ãšå®Ÿéš›ã®å·®åˆ†ã‹ã‚‰è¨ˆç®—ã—ã¦ãã ã•ã„ã€‚

6. **ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œå‡º**
   - ä¸€æ‹¬å¤‰æ›´ã®å¯èƒ½æ€§ï¼ˆåŒã˜å¤‰æ›´ãŒè¤‡æ•°ç®‡æ‰€ï¼‰
   - é–¢é€£ã™ã‚‹å¤‰æ›´ã®ã‚°ãƒ«ãƒ¼ãƒ—åŒ–

# å‡ºåŠ›å½¢å¼
JSON å½¢å¼ã§ä»¥ä¸‹ã®æ§‹é€ ã‚’è¿”ã—ã¦ãã ã•ã„ï¼š

âš ï¸ **é‡è¦**:
- statistics ã®å€¤ã¯å¿…ãšå®Ÿéš›ã®å·®åˆ†ã‹ã‚‰æ•°ãˆã¦ãã ã•ã„ã€‚ä¾‹ã®æ•°å€¤ã‚’ä½¿ã‚ãªã„ã§ãã ã•ã„ã€‚
- ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚„æ¨å¥¨äº‹é …ã¯å«ã‚ãªã„ã§ãã ã•ã„ã€‚äº‹å®Ÿã®ã¿ã‚’è¨˜è¼‰ã—ã¦ãã ã•ã„ã€‚
- yaml_path ã¯å…·ä½“çš„ãªéšå±¤æ§‹é€ ã‚’ç¤ºã—ã¦ãã ã•ã„ï¼ˆä¾‹: workflow.graph.nodes[0].data.model.nameï¼‰

{
  "summary": "å¤‰æ›´å†…å®¹ã®è¦ç´„ï¼ˆæ—¥æœ¬èªã€1-2æ–‡ã€å…·ä½“çš„ãªæŠ€è¡“ç”¨èªã‚’å«ã‚ã‚‹ï¼‰",
  "statistics": {
    "total_diff_lines": <å®Ÿéš›ã®å·®åˆ†è¡Œæ•°ï¼ˆ+ ã¾ãŸã¯ - ã§å§‹ã¾ã‚‹è¡Œã®ç·æ•°ï¼‰>,
    "added_lines": <+ ã§å§‹ã¾ã‚‹è¡Œã®å®Ÿéš›ã®æ•°ï¼ˆä¾‹: +   title: ãªã©ï¼‰>,
    "removed_lines": <- ã§å§‹ã¾ã‚‹è¡Œã®å®Ÿéš›ã®æ•°ï¼ˆä¾‹: -   title: ãªã©ï¼‰>,
    "affected_nodes": <title ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒè¿½åŠ ã¾ãŸã¯å‰Šé™¤ã•ã‚ŒãŸãƒãƒ¼ãƒ‰ã®å®Ÿéš›ã®æ•°>,
    "affected_edges": <id ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã« -source- ã‚’å«ã‚€ã‚¨ãƒƒã‚¸ã®è¿½åŠ ãƒ»å‰Šé™¤ã®å®Ÿéš›ã®æ•°>
  },
  "changes": [
    {
      "type": "added|modified|removed",
      "yaml_path": "workflow.graph.nodes[0].data.model.name",
      "location": "å¤‰æ›´ç®‡æ‰€ã®è¡Œç•ªå·ï¼ˆä¾‹: L142-L145ï¼‰",
      "description": "å…·ä½“çš„ãªå¤‰æ›´å†…å®¹ï¼ˆBefore â†’ After ã®å½¢å¼ã§è¨˜è¼‰ï¼‰",
      "before_value": "å¤‰æ›´å‰ã®å…·ä½“çš„ãªå€¤ï¼ˆè©²å½“ã™ã‚‹å ´åˆï¼‰",
      "after_value": "å¤‰æ›´å¾Œã®å…·ä½“çš„ãªå€¤ï¼ˆè©²å½“ã™ã‚‹å ´åˆï¼‰",
      "count": 1
    }
  ],
  "patterns": [
    {
      "description": "æ¤œå‡ºã•ã‚ŒãŸãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆä¾‹: ä¸€æ‹¬å¤‰æ›´ã€ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ç§»è¡Œï¼‰",
      "occurrences": <ãã®ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒå®Ÿéš›ã«å‡ºç¾ã—ãŸå›æ•°>
    }
  ]
}
"""


def analyze_diff_with_llm(diff_text: str, model: str = "gpt-5.1") -> dict:
    """
    LLM ã§å·®åˆ†ã‚’è§£æ

    Args:
        diff_text: å·®åˆ†ãƒ†ã‚­ã‚¹ãƒˆ
        model: ä½¿ç”¨ã™ã‚‹ LLM ãƒ¢ãƒ‡ãƒ«

    Returns:
        è§£æçµæœã®è¾æ›¸
    """
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        raise ValueError("OPENAI_API_KEY environment variable is not set")

    client = OpenAI(api_key=api_key)

    print(f"ğŸ¤– Analyzing diff with {model}...")

    try:
        response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": SYSTEM_PROMPT},
                {"role": "user", "content": f"ä»¥ä¸‹ã® Dify DSL ã®å·®åˆ†ã‚’è§£æã—ã¦ãã ã•ã„ï¼š\n\n```diff\n{diff_text}\n```"}
            ],
            temperature=0.3,  # ä¸€è²«æ€§ã®ã‚ã‚‹å‡ºåŠ›ã®ãŸã‚ä½ã‚ã«è¨­å®š
            response_format={"type": "json_object"}
        )

        result = json.loads(response.choices[0].message.content)

        print(f"âœ… Analysis complete")
        print(f"ğŸ“Š Tokens used: {response.usage.total_tokens}")

        return result

    except Exception as e:
        print(f"âŒ Error during LLM analysis: {e}", file=sys.stderr)
        raise


def format_analysis_as_markdown(analysis: dict) -> str:
    """
    è§£æçµæœã‚’ Markdown å½¢å¼ã«æ•´å½¢

    Args:
        analysis: LLM ã‹ã‚‰ã®è§£æçµæœ

    Returns:
        Markdown å½¢å¼ã®æ–‡å­—åˆ—
    """
    # Type ã®ã‚¢ã‚¤ã‚³ãƒ³
    type_icons = {
        "added": "â•",
        "modified": "ğŸ“",
        "removed": "â–"
    }

    md = f"""## ğŸ” Dify DSL å·®åˆ†è§£æãƒ¬ãƒãƒ¼ãƒˆ

**è¦ç´„**: {analysis.get('summary', 'å·®åˆ†ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ')}

---

"""

    # çµ±è¨ˆæƒ…å ±ã®è¿½åŠ 
    stats = analysis.get('statistics', {})
    if stats:
        md += f"""### ğŸ“Š å¤‰æ›´çµ±è¨ˆ

- **ç·å·®åˆ†è¡Œæ•°**: {stats.get('total_diff_lines', 'N/A')} è¡Œ
- **è¿½åŠ **: {stats.get('added_lines', 'N/A')} è¡Œ
- **å‰Šé™¤**: {stats.get('removed_lines', 'N/A')} è¡Œ
- **å½±éŸ¿ã‚’å—ã‘ã‚‹ãƒãƒ¼ãƒ‰æ•°**: {stats.get('affected_nodes', 'N/A')} å€‹
- **å½±éŸ¿ã‚’å—ã‘ã‚‹ã‚¨ãƒƒã‚¸æ•°**: {stats.get('affected_edges', 'N/A')} å€‹

---

"""

    md += """<details>
<summary>ğŸ“‹ å¤‰æ›´ä¸€è¦§ã‚’è¡¨ç¤º</summary>

### ğŸ“‹ å¤‰æ›´ä¸€è¦§

"""

    changes = analysis.get('changes', [])
    if not changes:
        md += "_å¤‰æ›´ãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ_\n\n"
    else:
        for i, change in enumerate(changes, 1):
            type_icon = type_icons.get(change.get('type', ''), 'â“')
            yaml_path = change.get('yaml_path', change.get('area', 'unknown'))  # å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ area ã‚‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯

            md += f"""#### {i}. {type_icon} {change.get('type', 'unknown').upper()} - `{yaml_path}`

"""

            # è¡Œç•ªå·ã®è¡¨ç¤º
            if change.get('location'):
                md += f"**è¡Œç•ªå·**: {change.get('location')}\n\n"

            md += f"{change.get('description', 'èª¬æ˜ãªã—')}\n"

            # Before/After ã®å€¤ã‚’è¡¨ç¤º
            if change.get('before_value') or change.get('after_value'):
                md += "\n```diff\n"
                if change.get('before_value'):
                    md += f"- {change.get('before_value')}\n"
                if change.get('after_value'):
                    md += f"+ {change.get('after_value')}\n"
                md += "```\n"

            # å¤‰æ›´ä»¶æ•°ã‚’è¡¨ç¤º
            if change.get('count', 1) > 1:
                md += f"\n- **å¤‰æ›´ç®‡æ‰€æ•°**: {change.get('count')} ç®‡æ‰€\n"

            md += "\n"

    md += "</details>\n\n"

    # ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æã®è¿½åŠ 
    patterns = analysis.get('patterns', [])
    if patterns:
        md += """---

### ğŸ” æ¤œå‡ºã•ã‚ŒãŸãƒ‘ã‚¿ãƒ¼ãƒ³

"""
        for pattern in patterns:
            md += f"- **{pattern.get('description', 'ä¸æ˜ãªãƒ‘ã‚¿ãƒ¼ãƒ³')}**: {pattern.get('occurrences', 0)} ç®‡æ‰€\n"
        md += "\n"

    md += """---

_ğŸ¤– ã“ã®è§£æã¯ LLM ã«ã‚ˆã‚Šè‡ªå‹•ç”Ÿæˆã•ã‚Œã¾ã—ãŸ_
"""

    return md


def main():
    if len(sys.argv) != 2:
        print(f"Usage: {sys.argv[0]} <diff.txt>", file=sys.stderr)
        print(f"\nExample:", file=sys.stderr)
        print(f"  {sys.argv[0]} diff.txt", file=sys.stderr)
        sys.exit(1)

    diff_path = Path(sys.argv[1])

    # å·®åˆ†ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
    if not diff_path.exists():
        print(f"âŒ Error: Diff file not found: {diff_path}", file=sys.stderr)
        sys.exit(1)

    # å·®åˆ†ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿
    try:
        with diff_path.open('r', encoding='utf-8') as f:
            diff_text = f.read()
    except Exception as e:
        print(f"âŒ Error: Failed to read diff file: {e}", file=sys.stderr)
        sys.exit(1)

    # ç©ºã®å·®åˆ†ã‚’ãƒã‚§ãƒƒã‚¯
    if not diff_text.strip():
        print("â„¹ï¸  No diff detected (empty file)")
        result = {
            "summary": "å·®åˆ†ãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ",
            "changes": [],
            "overall_impact": "low"
        }
        print(json.dumps(result, ensure_ascii=False, indent=2))
        sys.exit(0)

    # LLM ã§è§£æ
    model = os.getenv("LLM_MODEL", "gpt-4o-mini")

    try:
        analysis = analyze_diff_with_llm(diff_text, model)
    except Exception as e:
        print(f"âŒ Fatal error: {e}", file=sys.stderr)
        sys.exit(1)

    # JSON å‡ºåŠ›
    print("\n" + "="*60)
    print("JSON Output:")
    print("="*60)
    print(json.dumps(analysis, ensure_ascii=False, indent=2))

    # Markdown å‡ºåŠ›
    markdown = format_analysis_as_markdown(analysis)
    output_path = diff_path.parent / f"{diff_path.stem}_analysis.md"

    try:
        with output_path.open('w', encoding='utf-8') as f:
            f.write(markdown)
        print(f"\nâœ… Markdown report saved to: {output_path}")
    except Exception as e:
        print(f"âš ï¸  Warning: Failed to save markdown: {e}", file=sys.stderr)

    # GitHub Actions ã® output ã«è¨­å®šã™ã‚‹ãŸã‚ã®æƒ…å ±ã‚’å‡ºåŠ›
    if os.getenv("GITHUB_OUTPUT"):
        try:
            with open(os.getenv("GITHUB_OUTPUT"), "a") as f:
                f.write(f"analysis_json<<EOF\n{json.dumps(analysis, ensure_ascii=False)}\nEOF\n")
                f.write(f"overall_impact={analysis.get('overall_impact', 'low')}\n")
        except Exception as e:
            print(f"âš ï¸  Warning: Failed to write to GITHUB_OUTPUT: {e}", file=sys.stderr)


if __name__ == '__main__':
    main()
